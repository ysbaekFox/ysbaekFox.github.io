---
published: true
layout: single
title: "[k8s] Kubernetes 중급편 정리"
category: k8s
tags:
comments: true
sidebar:
  nav: "mainMenu"
---
* * *

## Pod의 LifeCycle
**1) Pending 단계**
- 제일 먼저 Pod가 Node에 정상적으로 할당되면 **PodScheduled**가 true가 된다. (사용자가 특정 노드에 직접 할당을 하든지, 쿠버네티스가 자원 상황에 따라 자동으로 하든지)
- 이후에 Container가 실행되기전에 사전설정해주어야하는 것들이 있다면 실행되는 InitContainer가 Pending 단계 때 실행 된다. (볼륨 / 보안 셋팅 등)
- pod의 yaml 정의 spec에 initContainers라는 항목을 추가하여 실행 가능 함, 이것이 성공 적으로 수행 되면 **Initialized** 값이 true가 된다. (InitContainer가 없어도 true)
- 이후 Container의 이미지를 다운로드하는 동작이 수행 되고, 지금까지 설명한 단계동안 Container의 Status는 Waiting 상태이고, Reason은 ContainerCreating 임.

**2) Running**
- 만약 Pod에서 Continaer를 정상적으로 실행하지 못한 경우 Container의 상태는 Waiting이 되고 Reason은 CrashLoopBackOff가 됨.
- CrashLoopBackOff 상태에서 Container의 상태는 Ready로 판단하지만 내부적으로 ContainerReady 와 Ready는 False가 임.
- 이후 모든 컨테이너들이 정상적으로 기동이 되어 원할하게 돌아가게 되면 ContainerReady와 Ready는 False가 됨.
- 그러므로 상황에 따라 Pod의 상태 뿐만 이나리 Container의 상태도 모니터링 할 필요가 있음.
- 만약 Job이나 CronJob으로 생성된 Pod의 경우, 일을 수행하고 있을 때는 Running이지만 일을 수행하고 나면 Failed / Succeeded가 된다. 

**3) Failed**
- Failed / Succeded 결과에 상관 없이 ContainerReady와 Ready는 모두 False가 된다.
- Container가 수행을 완료하지 못한 경우 Terminated / Error가 된다.

**4) Succeeded**
- Failed / Succeded 결과에 상관 없이 ContainerReady와 Ready는 모두 False가 된다.
- Container가 수행을 완료한 경우 Terminated / Completed 된다.

**5) Unknown**
- Pending 중에 바로 Failed 혹은 Unkown 상태가 되는 경우도 있음.

## Pod - ReadinessProbe / LivenessProbe
- ReadinessProbe: 앱이 구동 되는 순간(부팅 과정)에 서비스와 연결 되자마자 전달 받은 Traffic에 대해 응답하지 못해 발생하는 문제를 해결하기 위한 기능.
- LivenessProbe: K8S 서비스와 적접적으로 연결된 Container에는 문제가 없으나 컨테이너 내부의 구동 중인 App에 문제가 생긴 경우 Service가 문제를 감지하여 Traffic 실패를 해결하기 위한 기능. 

**사용 방법**
- 사용 목적이 다를 뿐 설정할 수 있는 내용은 ReadinessProbe와 LivenessProbe가 같습니다.
- httpGet / Exec / tcpSocket 이라는 필수 옵션이 있음.
- initialDealySeconds / periodSeconds / timeoutSeconds / successThreshold / failureThreshold 라는 선택 옵션이 있음. 각각 0초 / 10초 / 1초 / 1회 / 3회 의 default 값을 가짐.
- Pod가 Running이 되더라도 Probe의 조건을 만족하지 못할 경우 ContainerReady와 Ready가 false에서 true로 변경되지 않음.

## ReadinessProbe / LivenessProbe 실습
<br>

**1) ReadinessProbe 실습**

<details>
<summary> yaml 펼치기 </summary>
<div markdown="1">

```yaml
# Service 정의
apiVersion: v1
kind: Service
metadata:
  name: svc-readiness
spec:
  selector:
    app: readiness
  ports:
  - port: 8080
    targetPort: 8080
---
# 일반 Pod 정의
apiVersion: v1
kind: Pod
metadata:
  name: pod1
  labels:
    app: readiness  
spec:
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080	
  terminationGracePeriodSeconds: 0
---
# rediness Pod 정의
apiVersion: v1
kind: Pod
metadata:
  name: pod-readiness-exec1
  labels:
    app: readiness  
spec:
  containers:
  - name: readiness
    image: kubetm/app
    ports:
    - containerPort: 8080	
    readinessProbe:
      exec:
        command: ["cat", "/readiness/ready.txt"]
      initialDelaySeconds: 5
      periodSeconds: 10
      successThreshold: 3
    volumeMounts:
    - name: host-path
      mountPath: /readiness
  volumes:
  - name : host-path
    hostPath:
      path: /tmp/readiness
      type: DirectoryOrCreate
  terminationGracePeriodSeconds: 0
```

</div>
</details>
<br>
아래와 같이 일반 pod와 readiness pod를 실행한 후 요청을 보내면 readiness pod로부터는 응답이 없는 것을 확인할 수 있습니다. (ready.txt 파일이 없으므로)

![image](https://github.com/ysbaekFox/ysbaekFox.github.io/assets/54944434/01b115f3-96d9-45ef-a8b1-196ae180e470)

몇가지 커맨드를 입력하여 pod의 상태를 확인해보도록 하겠습니다.

```shell
$ kubectl get events -w | grep pod-readiness-exec1
$ kubectl describe pod pod-readiness-exec1 | grep -A5 Conditions
$ kubectl describe endpoints svc-readiness
```

우선 ready.txt 파일을 찾을 수 없구요, Conditions를 보면 ContainersReady와 Ready 값이 false 입니다. 
그리고 NotReadyAddresses를 확인해보면 readiness-pod의 IP를 확인할 수도 있네요.

![image](https://github.com/ysbaekFox/ysbaekFox.github.io/assets/54944434/ea3934cc-5eb8-479e-b8b2-203dc0f3fb76)

이후에 readiness pod가 실행 중인 node에 접속하여 ready.txt 파일을 생성해주니 정상적으로 응답하는 것을 확인할 수 있었습니다.

![image](https://github.com/ysbaekFox/ysbaekFox.github.io/assets/54944434/045b34c8-19af-43c3-93e7-d04272135293)

<br>

**2) LivenessProbe 실습**

LivenessProbe 실습을 해보겠습니다. livenessProbe를 가지는 Pod를 생성하고 테스트해보도록 하겠습니다.

<details>
<summary> yaml 펼치기 </summary>
<div markdown="1">

```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-liveness
spec:
  selector:
    app: liveness
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: v1
kind: Pod
metadata:
  name: pod2
  labels:
    app: liveness
spec:
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-liveness-httpget1
  labels:
    app: liveness
spec:
  containers:
  - name: liveness
    image: kubetm/app
    ports:
    - containerPort: 8080
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 10
      failureThreshold: 3
  terminationGracePeriodSeconds: 0
```
</div>
</details>
<br>
현재 LivenessProbe가 정상적으로 동작 중인 것을 확인할 수 있습니다.

![image](https://github.com/ysbaekFox/ysbaekFox.github.io/assets/54944434/9073061b-a468-438b-9688-abb438edf87a)

이번엔 강제로 status 500을 전달하여 pod의 상태가 어떻게 변화하는지 확인해보겠습니다. status500을 3번 전달하니 LivenessProbe가 Container에 이상이 생겼음을 감지하고 Container를 재시작하는 것을 확인할 수 있었습니다.

![image](https://github.com/ysbaekFox/ysbaekFox.github.io/assets/54944434/b84dabe5-65cb-4b04-8e9e-af351ddfd928)

## QoS classes (Guaranteed / Burstable / BestEffort)

Node에 균등하게 자원을 사용하는 Pod가 여러개 동작하고 있다고 가정할 떄, 
그 중 한개의 Pod가 자원을 추가적으로 사용해야하는 상황에서 추가 자원이 없는 경우 어떻게 동작할지에 대해 정의하는 기능 입니다. 쿠버네티스에서는 앱의 중요도에 따라 이것을 Control할 수 있도록 QoS라는 기능을 제공하고 있습니다. 그러한 Pod들은 중요도 순으로 BestEffort < Burstable < Guranteed로 구분 됩니다.  

특이한 점은 따로 QoS 구분을 위한 정의부가 있는 것이 아니라 spec의 resources / requetes / limits이 정의가 어떻게 되어 있냐에 따라 자동으로 설정 됩니다.

**1) Guaranteed**
- Pod의 모든 Container에 Request와 Limit가 설정되어 있어야 한다.
- Request와 Limit에는 Memory와 CPU가 모두 설정되어 있어야 한다.
- 각 Container 내의 Memory와 CPU의 Reuqest와 Limit의 값이 같아야 한다.

**2) Burstable**
- Guaranteed / BestEffort가 아닌 모든 경우
- 그렇다면 같은 Burstable Pod 간에는 OOM Score가 더 높은 것이 먼저 삭제 된다. (OOM Score는 Request Memory 대비 실제 App의 Memory 사용량)

**3) BestEffort**
- 어떤 Container 내에도 Request와 Limit이 설정되지 않은 경우.

## Pod의 Node Scheduling

![image](https://github.com/ysbaekFox/ysbaekFox.github.io/assets/54944434/de45f574-c2e3-4bdb-a9ab-d59893cae664)