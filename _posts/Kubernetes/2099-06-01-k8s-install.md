---
published: true
layout: single
title: "[k8s] 쿠버네티스 클러스터 구성"
category: k8s
tags:
comments: true
sidebar:
  nav: "mainMenu"
--- 
* * *

이유는 알 수 없지만, 쿠버네티스 가비지 컬렉션이 동작하지 않는 문제가 발생하였습니다.
아래 명령어로 kube-controller-manager-master pod의 로그를 살펴보니 원인을 찾을 수 없는 로그가 너무 많이 나왔고, 결국 완전히 삭제하고 다시 설치하기로 했습니다.
모든 과정을 자세하게 기재하지 않았지만, 설치하는 과정에서 발생했던 오류들을 정리하였습니다.

## kubeadm 설치
- [Reference Page](https://kubernetes.io/ko/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)

데비안 기반 배포판으로 설치할 예정입니다.

1) apt 패키지 색인을 업데이트하고, 쿠버네티스 apt 리포지터리를 사용하는 데 필요한 패키지를 설치합니다.
```shell
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates cur
```
```shell
ysbaek@master:~$ sudo apt-get install -y apt-transport-https ca-certificates curl
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
ca-certificates is already the newest version (20230311ubuntu0.22.04.1).
ca-certificates set to manually installed.
The following NEW packages will be installed:
  apt-transport-https curl
0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.
```

<br>

2) 구글 클라우드의 공개 사이닝 키를 다운로드 합니다.
```shell
sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
```

<br>

3) 쿠버네티스 apt 리포지터리를 추가합니다.
```
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
```
```shell
ysbaek@master:~$ sudo apt-get update
Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease
Get:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [8,993 B]
Err:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease
  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05
...
...
```

<br>

4) 그런데 apt 리포지터리를 업데이트하는 도중에 에러가 발생했습니다. 다음 과정을 통해 해결하였습니다.

```shell
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | gpg --dearmor | sudo dd status=none of=/usr/share/keyrings/kubernetes-archive-keyring.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
```

```shell
The following additional packages will be installed:
  conntrack cri-tools ebtables kubernetes-cni socat
The following NEW packages will be installed:
  conntrack cri-tools ebtables kubeadm kubectl kubelet kubernetes-cni socat
0 upgraded, 8 newly installed, 0 to remove and 0 not upgraded.
Need to get 85.8 MB of archives.
After this operation, 329 MB of additional disk space will be used.
Get:2 http://kr.archive.ubuntu.com/ubuntu jammy/main amd64 conntrack amd64 1:1.4.6-2build2 [33.5 kB]
Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 cri-tools amd64 1.26.0-00 [18.9 MB]
Get:7 http://kr.archive.ubuntu.com/ubuntu jammy/main amd64 ebtables amd64 2.0.11-4build2 [84.9 kB]
Get:8 http://kr.archive.ubuntu.com/ubuntu jammy/main amd64 socat amd64 1.7.4.1-3ubuntu4 [349 kB]
Get:3 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubernetes-cni amd64 1.2.0-00 [27.6 MB]
Get:4 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.27.3-00 [18.7 MB]
Get:5 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.27.3-00 [10.2 MB]
Get:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.27.3-00 [9,918 kB]
```

<br>

5) kubelet, kubeadm, kubectl을 설치하고 해당 버전을 고정합니다.
```shell
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```

## Containerd 설치
1) Containerd 다운로드 및 압축 해제를 진행합니다.
```shell
wget https://github.com/containerd/containerd/releases/download/v1.7.2/containerd-1.7.2-linux-amd64.tar.gz
```
```shell
tar Cxzvf /usr/local https://github.com/containerd/containerd/releases/download/v1.7.2/containerd-1.7.2-linux-amd64.tar.gz
```

2) sysetmd에서 containerd 서비스 실행을 위한 service 정의 팡리 다운로드 및 경로를 이동하여 줍니다.
```shell
wget https://raw.githubusercontent.com/containerd/containerd/main/containerd.service
sudo mv ./containerd.service /usr/local/lib/systemd/system/containerd.service
```

3. containerd가 정상적으로 구동중인 것 확인을 확인합니다.
```shell
systemctl daemon-reload
systemctl enable --now containerd
```

```shell
● containerd.service - containerd container runtime
     Loaded: loaded (/lib/systemd/system/containerd.service; enabled; vendor preset: enabled)
     Active: active (running) since Mon 2023-06-19 00:20:33 KST; 57s ago
       Docs: https://containerd.io
    Process: 13105 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCCESS)
   Main PID: 13107 (containerd)
      Tasks: 12
     Memory: 54.5M
        CPU: 138ms
     CGroup: /system.slice/containerd.service
             └─13107 /usr/local/bin/containerd

 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.174528396+09:00" level=info msg=serving... address=/run/containerd/contai>
 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.174564674+09:00" level=info msg="Start subscribing containerd event"
 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.175367554+09:00" level=info msg="Start recovering state"
 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.174583919+09:00" level=info msg=serving... address=/run/containerd/contai>
 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.175456119+09:00" level=info msg="Start event monitor"
 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.175510550+09:00" level=info msg="Start snapshots syncer"
 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.175526439+09:00" level=info msg="Start cni network conf syncer for defaul>
 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.175546837+09:00" level=info msg="Start streaming server"
 6월 19 00:20:33 master systemd[1]: Started containerd container runtime.
 6월 19 00:20:33 master containerd[13107]: time="2023-06-19T00:20:33.176135681+09:00" level=info msg="containerd successfully booted in 0.0571>
 ```

## kubadm을 사용한 클러스터 구성.
- [Calico Install on k8s](https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart)

Calico를 사용하여 쿠버네티스 클러스터를 구성해보도록 하겠습니다.
kubadm을 사용하여 init 명령어를 수행해줍니다. 참고로 저의 local master node 주소는 192.168.0.100이므로 각자의 환경에 맞게 입력해주도록 합니다.
```shell
sudo kubeadm init --pod-network-cidr=192.168.0.100/16
```


#### swapoff enable Error

```shell
sudo swapoff -a
```

#### Cluster 환경 CPU 개수 Error

저는 VBoxManager를 사용하여 가상 환경으로 노드를 구성하였는데요, 깜빡하고 cpu 개수를 1개로 지정해놓아서 아래와 같은 에러가 발생하였습니다. 
해결하는 방법은 cpu 개수를 2개 이상으로 재할당 해주면 됩니다.
```shell
[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2               
```

먼저 host 환경의 cpu 개수를 확인해줍시다.
```shell
(base) ysbaek@ysbaek:~$ lscpu | grep '^CPU(s):'
CPU(s): 32
```

가상환경을 종료하고 아래 명령어로 적절하게 할당해 줍니다. (저의 가상환경 이름은 master 입니다.)
```shell
VBoxManage modifyvm master --cpus {cpu count}
```

#### 패킷 포워딩 옵션 Error
```shell
[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1
```

/etc/sysctl.conf를 열어 net.ipv4.ip_forward=1행의 주석을 제거

이후 변경된 설정 적용을 위해 아래 명령어 실행
```
sysctl -p
```

#### bridge 관련 설정 Error
```shell
[ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
```

아래 커맨드 입력, 참고로 root로 접속하지 않고 커맨드를 sudo로 입력할 경우 권한이 제대로 작동하지 않는 문제가 있었습니다.
```
su
modprobe br_netfilter
echo 1 > /proc/sys/net/bridge/bridge-nf-call-iptables
```


자 다시 kubeadm init 커맨드를 입력해보도록 합시다. 저는 이제 정상적으로 설치가 진행 되네요.

```shell
kubectl logs -f kube-controller-manager-master -n kube-system
```


## Calico 설치

Step 2: Installing runc
```shell
wget https://github.com/opencontainers/runc/releases/download/v1.1.7/runc.amd64
install -m 755 runc.amd64 /usr/local/sbin/runc
```

Step 3: Installing CNI plugins
```
wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz
mkdir -p /opt/cni/bin
tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.3.0.tgz
```

```

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

```

```
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.0/manifests/tigera-operator.yaml
```

```
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.0/manifests/custom-resources.yaml
```


kubeadm join 192.168.0.100:6443 --token suqkd4.m9ccluyv6clcgvf5 \
        --discovery-token-ca-cert-hash sha256:9717114f1f18777afe77595f2844562e8f50d12813ec4878ddaa9c1cc3d477a9


<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

```shell
..................
..................
..................
E0613 11:27:17.563908       1 garbagecollector.go:250] timed out waiting for dependency graph builder sync during GC sync (attempt 20335)
I0613 11:27:17.664013       1 shared_informer.go:270] Waiting for caches to sync for garbage collector
E0613 11:27:47.664679       1 shared_informer.go:273] unable to sync caches for garbage collector
E0613 11:27:47.664707       1 garbagecollector.go:250] timed out waiting for dependency graph builder sync during GC sync (attempt 20336)
I0613 11:27:47.763819       1 shared_informer.go:270] Waiting for caches to sync for garbage collector
W0613 11:27:50.484268       1 reflector.go:424] vendor/k8s.io/client-go/metadata/metadatainformer/informer.go:90: failed to list *v1.PartialObjectMetadata: connection is unauthorized: bgpfilters.crd.projectcalico.org is forbidden: User "system:serviceaccount:calico-apiserver:calico-apiserver" cannot list resource "bgpfilters" in API group "crd.projectcalico.org" at the cluster scope
E0613 11:27:50.484304       1
..................
..................
..................
 reflector.go:140] vendor/k8s.io/client-go/metadata/metadatainformer/informer.go:90: Failed to watch *v1.PartialObjectMetadata: failed to list *v1.PartialObjectMetadata: connection is unauthorized: bgpfilters.crd.projectcalico.org is forbidden: User "system:serviceaccount:calico-apiserver:calico-apiserver" cannot list resource "bgpfilters" in API group "crd.projectcalico.org" at the cluster scope
E0613 11:30:18.166260       1 shared_informer.go:273] unable to sync caches for garbage collector
E0613 11:30:18.166293       1 garbagecollector.go:250] timed out waiting for dependency graph builder sync during GC sync (attempt 20341)
I0613 11:30:18.266867       1 shared_informer.go:270] Waiting for caches to sync for garbage collector
E0613 11:30:48.267190       1 shared_informer.go:273] unable to sync caches for garbage collector
E0613 11:30:48.267230       1 garbagecollector.go:250] timed out waiting for dependency graph builder sync during GC sync (attempt 20342)
```

<br>

# 쿠버네티스 삭제
먼저 설치 전에 삭제부터 진행 합니다.
- 구성한 Work Node에서 kubeadm reset 실행 및 systemctl stop kubelet 입력 (Node 삭제 및 kubernetes 종료)
- Master Node에서 sudo kubeadm reset 실행 및 systemctl stop kubelet 입력 (Node 삭제 및 kubernetes 종료)

그리고 기타 폴더 및 lib 삭제, 참고로 저는 containered를 CNI로 사용했기에 혹시 몰라서 재설치해주려고 삭제해주었습니다. 
```shell
sudo rm -rf /var/lib/cni/
sudo rm -rf /var/lib/kubelet/
sudo rm -rf /var/lib/etcd/
sudo rm -rf /var/lib/containerd/
sudo rm -rf /etc/cni
sudo rm -rf /etc/kubernetes/
sudo rm -rf ~/.kube
sudo rm -rf /usr/bin/containerd*
sudo rm -rf /usr/bin/ctr
sudo rm -rf /etc/containerd
```

또 추가로 삭제해 줍니다. 그리고 시스템을 재시작 해줍니다.
```shell
sudo apt-get purge kubeadm kubectl kubelet kubernetes-cni kube* -y
sudo apt-get autoremove -y
```


```shell
sudo systemctl daemon-reload
sudo systemctl stop kubelet
```

자 이제 다시 하나씩 설치해보도록 하자.

<br>

# containered 설치
쿠버네티스는 파에서 컨테이너를 실행하기 위해 표준으로 containered를 사용한다. 그래서 먼저 containered를 설치해보도록 하겠다.
  
사실 containered는 Ubuntu 배포판에 포함이 되어 있어야 하는건데... 내가 뭐 실수로 이것저것 깔앗디 지웟다 하다보니 배포판에 있던 기본 버전은 뭔지도 모르겠고, 이제 복구도 불가능하다.
일단 아키텍처에 맞는 버전을 사용해야 하는데 확인해보니 내 우분투 환경은 x86_64(amd64)였다. 설치 후 /user/local에 압축 풀어주자.

```shell
sudo rm -rf /usr/bin/ctr
sudo rm -rf /usr/bin/containerd*
sudo rm -rf /usr/local/ctr
sudo rm -rf /usr/local/containerd*
wget https://github.com/containerd/containerd/releases/download/v1.7.2/containerd-1.7.2-linux-amd64.tar.gz
sudo tar Cxzvf /usr containerd-1.7.2-linux-amd64.tar.gz
sudo tar Cxzvf /usr/local containerd-1.7.2-linux-amd64.tar.gz
```

runc 설치
```shell
wget https://github.com/opencontainers/runc/releases/download/v1.1.7/runc.amd64
sudo mkdir -p /usr/local/sbin/runc
sudo install -m 755 runc.amd64 /usr/local/sbin/runc
```

cni plugin 설치
```shell
wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz
sudo rm -rf /opt/cni/bin
sudo mkdir -p /opt/cni/bin
sudo tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.3.0.tgz
```

"/etc/containerd"를 만듭니다. 그런 다음 아래와 같이 "containerd" 명령을 사용하여 기본 Containerd 구성을 생성합니다.
```shell
sudo mkdir -p /etc/containerd/
containerd config default | sudo tee /etc/containerd/config.toml
```
Containerd 컨테이너 런타임에 대해 "SystemdCgroup"을 활성화합니다. 
이 명령은 Containerd 구성 파일 "/etc/containerd/에서 "SystemdCgroup = false" 옵션을 "SystemdCgroup = true"로 대체합니다.
```shell
sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml
```

Containerd용 systemd 서비스 파일을 "/etc/systemd/system" 디렉터리에 다운로드합니다.
```shell
sudo curl -L https://raw.githubusercontent.com/containerd/containerd/main/containerd.service -o /etc/systemd/system/containerd.service
```

systemd 관리자를 다시 로드하여 새 서비스 파일을 적용합니다. 그리고 "containerd" 서비스를 시작하고 활성화합니다.
설치에 성공하면 프로세스를 시작하는 "containerd" 서비스 중에 오류 메시지가 표시되지 않습니다.
```shell
sudo systemctl daemon-reload
sudo systemctl start containerd
sudo systemctl enable containerd
```

자 최종적으로 아래와 같이 systemd service에 containerd 실행 중인 것 확인.
```shell
systemctl | grep containerd
  containerd.service  loaded active running   containerd container runtime
```

systemctl status containerd
![image](https://github.com/ysbaekFox/ysbaekFox.github.io/assets/54944434/832865dc-1249-448a-9de3-f048c0228437)

<br>

# kubeadm, kubelet 및 kubectl 설치
설치 전에 간단히 어떤 역할을 하는 것들인지 알아보자.
- kubeadm: 클러스터를 부트스트랩하는 명령이다.
- kubelet: 클러스터의 모든 머신에서 실행되는 파드와 컨테이너 시작과 같은 작업을 수행하는 컴포넌트이다.
- kubectl: 클러스터와 통신하기 위한 커맨드 라인 유틸리티이다.

Update the apt package index and install packages needed to use the Kubernetes apt repository:
```shell
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl
```

Download the Google Cloud public signing key:
```shell
sudo mkdir -p /etc/apt/keyrings
sudo curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpg
```

Add the Kubernetes apt repository
```shell
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
```

```shell
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```

<br>

# Calico 설치



# Calico로 Master Node 구성. (Only Master)
나는 이미 구성된 시스템 환경이 있어서 IP를 192.168.0.100으로 설정하였다.
```shell
sudo rm -rf /etc/kubernetes/manifests \
              /var/lib/kubelet \
              /etc/kubernetes/pki \
              /etc/kubernetes/admin.conf \
              /etc/kubernetes/kubelet.conf \
              /etc/kubernetes/bootstrap-kubelet.conf \
              /etc/kubernetes/controller-manager.conf \
              /etc/kubernetes/scheduler.conf
```

sudo kubeadm init --pod-network-cidr=192.168.0.100/16

worker node에서 실행할 join 명령어와 token은 따로 저장해두자.
```shell
kubeadm join 192.168.0.100:6443 --token jqntxt.qh9454lsjmi2i0ib --discovery-token-ca-cert-hash sha256:52e15eca02e13eb1918a43ce41b7243401029613654fbc0cb1638689b3512c22
```

```shell
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

```shell
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.0/manifests/tigera-operator.yaml
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.0/manifests/custom-resources.yaml
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
kubectl taint nodes --all node-role.kubernetes.io/master-
```

![image](https://github.com/ysbaekFox/ysbaekFox.github.io/assets/54944434/6f0df363-0b3b-4c8d-b445-7f01b9ad772d)


